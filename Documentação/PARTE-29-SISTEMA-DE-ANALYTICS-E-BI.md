# PARTE 29: SISTEMA DE ANALYTICS E BI

## üìä Descri√ß√£o
Sistema completo de analytics e business intelligence para a plataforma KRYONIX, incluindo coleta de dados, processamento em tempo real, dashboards interativos, relat√≥rios automatizados e intelig√™ncia artificial para insights preditivos.

## üéØ Objetivos
- Implementar coleta de dados abrangente de todas as opera√ß√µes
- Criar sistema de processamento de dados em tempo real
- Desenvolver dashboards interativos personaliz√°veis
- Configurar relat√≥rios automatizados e alertas inteligentes
- Integrar IA para an√°lises preditivas e recomenda√ß√µes
- Garantir conformidade com LGPD/GDPR na coleta de dados

## üèóÔ∏è Arquitetura

```mermaid
graph TB
    subgraph "KRYONIX Analytics & BI"
        subgraph "Data Collection Layer"
            DC[Data Collectors]
            EL[Event Listeners]
            API[Analytics API]
        end
        
        subgraph "Processing Layer"
            RT[Real-time Processor]
            BT[Batch Processor]
            ETL[ETL Pipeline]
            ML[ML Pipeline]
        end
        
        subgraph "Storage Layer"
            TS[TimescaleDB]
            CH[ClickHouse]
            ES[Elasticsearch]
            DW[Data Warehouse]
        end
        
        subgraph "Analytics Layer"
            DS[Dashboard Service]
            RS[Report Service]
            AS[Alert Service]
            AI[AI Insights]
        end
        
        subgraph "Frontend Layer"
            WD[Web Dashboards]
            MD[Mobile Dashboards]
            RE[Report Export]
            VZ[Visualizations]
        end
    end
    
    DC --> RT
    EL --> RT
    API --> RT
    RT --> TS
    BT --> CH
    ETL --> DW
    ML --> ES
    
    DS --> TS
    RS --> CH
    AS --> DW
    AI --> ES
    
    DS --> WD
    RS --> RE
    AS --> MD
    AI --> VZ
```

## üìä Base de Dados

### Schema PostgreSQL com TimescaleDB

```sql
-- ==================================================
-- KRYONIX ANALYTICS & BI - POSTGRESQL SCHEMA
-- ==================================================

-- Extens√µes necess√°rias
CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- Schema dedicado para analytics
CREATE SCHEMA IF NOT EXISTS analytics;
SET search_path TO analytics, public;

-- =====================================================
-- TABELAS DE EVENTOS E M√âTRICAS
-- =====================================================

-- Eventos do sistema (hypertable para s√©ries temporais)
CREATE TABLE IF NOT EXISTS system_events (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    tenant_id UUID NOT NULL,
    user_id UUID,
    session_id VARCHAR(255),
    event_type VARCHAR(100) NOT NULL,
    event_category VARCHAR(50) NOT NULL,
    event_action VARCHAR(100) NOT NULL,
    event_label VARCHAR(255),
    event_value DECIMAL(15,2),
    properties JSONB,
    metadata JSONB,
    ip_address INET,
    user_agent TEXT,
    referrer TEXT,
    page_url TEXT,
    device_type VARCHAR(50),
    platform VARCHAR(50),
    browser VARCHAR(50),
    location_country VARCHAR(2),
    location_city VARCHAR(100),
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    processed BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Converter para hypertable (TimescaleDB)
SELECT create_hypertable('system_events', 'timestamp', 
    chunk_time_interval => INTERVAL '1 day',
    if_not_exists => TRUE
);

-- M√©tricas de performance
CREATE TABLE IF NOT EXISTS performance_metrics (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    tenant_id UUID NOT NULL,
    service_name VARCHAR(100) NOT NULL,
    endpoint VARCHAR(255),
    method VARCHAR(10),
    response_time INTEGER, -- em ms
    memory_usage BIGINT, -- em bytes
    cpu_usage DECIMAL(5,2), -- percentual
    disk_usage BIGINT, -- em bytes
    network_in BIGINT, -- bytes
    network_out BIGINT, -- bytes
    error_count INTEGER DEFAULT 0,
    success_count INTEGER DEFAULT 0,
    status_code INTEGER,
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_at TIMESTAMPTZ DEFAULT NOW()
);

SELECT create_hypertable('performance_metrics', 'timestamp',
    chunk_time_interval => INTERVAL '1 hour',
    if_not_exists => TRUE
);

-- M√©tricas de neg√≥cio
CREATE TABLE IF NOT EXISTS business_metrics (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    tenant_id UUID NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    metric_type VARCHAR(50) NOT NULL, -- counter, gauge, histogram
    metric_value DECIMAL(15,4) NOT NULL,
    dimensions JSONB,
    tags JSONB,
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_at TIMESTAMPTZ DEFAULT NOW()
);

SELECT create_hypertable('business_metrics', 'timestamp',
    chunk_time_interval => INTERVAL '1 day',
    if_not_exists => TRUE
);

-- =====================================================
-- DASHBOARDS E RELAT√ìRIOS
-- =====================================================

-- Dashboards configur√°veis
CREATE TABLE IF NOT EXISTS dashboards (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    tenant_id UUID NOT NULL,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    config JSONB NOT NULL,
    layout JSONB NOT NULL,
    widgets JSONB NOT NULL,
    filters JSONB,
    refresh_interval INTEGER DEFAULT 300, -- segundos
    is_public BOOLEAN DEFAULT FALSE,
    is_default BOOLEAN DEFAULT FALSE,
    created_by UUID NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Widgets dos dashboards
CREATE TABLE IF NOT EXISTS dashboard_widgets (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    dashboard_id UUID NOT NULL REFERENCES dashboards(id) ON DELETE CASCADE,
    widget_type VARCHAR(50) NOT NULL,
    title VARCHAR(255) NOT NULL,
    config JSONB NOT NULL,
    query JSONB NOT NULL,
    position JSONB NOT NULL,
    size JSONB NOT NULL,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Relat√≥rios automatizados
CREATE TABLE IF NOT EXISTS reports (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    tenant_id UUID NOT NULL,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    report_type VARCHAR(50) NOT NULL,
    query JSONB NOT NULL,
    template JSONB NOT NULL,
    schedule JSONB,
    recipients JSONB,
    format VARCHAR(20) DEFAULT 'PDF',
    is_active BOOLEAN DEFAULT TRUE,
    last_run TIMESTAMPTZ,
    next_run TIMESTAMPTZ,
    created_by UUID NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Execu√ß√µes de relat√≥rios
CREATE TABLE IF NOT EXISTS report_executions (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    report_id UUID NOT NULL REFERENCES reports(id) ON DELETE CASCADE,
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    started_at TIMESTAMPTZ,
    completed_at TIMESTAMPTZ,
    file_path TEXT,
    file_size BIGINT,
    error_message TEXT,
    execution_time INTEGER, -- segundos
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- =====================================================
-- ALERTAS E NOTIFICA√á√ïES
-- =====================================================

-- Regras de alerta
CREATE TABLE IF NOT EXISTS alert_rules (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    tenant_id UUID NOT NULL,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    metric_name VARCHAR(100) NOT NULL,
    condition JSONB NOT NULL,
    threshold_value DECIMAL(15,4) NOT NULL,
    comparison_operator VARCHAR(10) NOT NULL,
    severity VARCHAR(20) NOT NULL,
    is_active BOOLEAN DEFAULT TRUE,
    notification_config JSONB NOT NULL,
    cooldown_period INTEGER DEFAULT 300, -- segundos
    created_by UUID NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Alertas disparados
CREATE TABLE IF NOT EXISTS alerts (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    rule_id UUID NOT NULL REFERENCES alert_rules(id),
    tenant_id UUID NOT NULL,
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    current_value DECIMAL(15,4) NOT NULL,
    threshold_value DECIMAL(15,4) NOT NULL,
    message TEXT NOT NULL,
    severity VARCHAR(20) NOT NULL,
    acknowledged BOOLEAN DEFAULT FALSE,
    acknowledged_by UUID,
    acknowledged_at TIMESTAMPTZ,
    resolved_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- =====================================================
-- AN√ÅLISES E INSIGHTS
-- =====================================================

-- An√°lises preditivas
CREATE TABLE IF NOT EXISTS predictive_analyses (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    tenant_id UUID NOT NULL,
    analysis_type VARCHAR(50) NOT NULL,
    model_name VARCHAR(100) NOT NULL,
    input_data JSONB NOT NULL,
    predictions JSONB NOT NULL,
    confidence_score DECIMAL(5,4),
    accuracy_score DECIMAL(5,4),
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Insights autom√°ticos
CREATE TABLE IF NOT EXISTS automated_insights (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    tenant_id UUID NOT NULL,
    insight_type VARCHAR(50) NOT NULL,
    title VARCHAR(255) NOT NULL,
    description TEXT NOT NULL,
    priority VARCHAR(20) NOT NULL,
    impact_score DECIMAL(5,2),
    recommendations JSONB,
    data_sources JSONB,
    validity_period INTERVAL,
    is_read BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    expires_at TIMESTAMPTZ
);

-- =====================================================
-- CONFIGURA√á√ïES E METADADOS
-- =====================================================

-- Fontes de dados
CREATE TABLE IF NOT EXISTS data_sources (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    tenant_id UUID NOT NULL,
    name VARCHAR(255) NOT NULL,
    type VARCHAR(50) NOT NULL,
    connection_config JSONB NOT NULL,
    schema_config JSONB,
    sync_frequency INTEGER DEFAULT 3600, -- segundos
    last_sync TIMESTAMPTZ,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Configura√ß√µes de reten√ß√£o
CREATE TABLE IF NOT EXISTS retention_policies (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    tenant_id UUID NOT NULL,
    table_name VARCHAR(100) NOT NULL,
    retention_period INTERVAL NOT NULL,
    compression_enabled BOOLEAN DEFAULT TRUE,
    compression_after INTERVAL DEFAULT '7 days',
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- =====================================================
-- √çNDICES PARA PERFORMANCE
-- =====================================================

-- √çndices para system_events
CREATE INDEX IF NOT EXISTS idx_system_events_tenant_timestamp 
ON system_events (tenant_id, timestamp DESC);

CREATE INDEX IF NOT EXISTS idx_system_events_type_timestamp 
ON system_events (event_type, timestamp DESC);

CREATE INDEX IF NOT EXISTS idx_system_events_user_timestamp 
ON system_events (user_id, timestamp DESC) WHERE user_id IS NOT NULL;

CREATE INDEX IF NOT EXISTS idx_system_events_properties 
ON system_events USING GIN (properties);

-- √çndices para performance_metrics
CREATE INDEX IF NOT EXISTS idx_performance_metrics_service_timestamp 
ON performance_metrics (service_name, timestamp DESC);

CREATE INDEX IF NOT EXISTS idx_performance_metrics_tenant_timestamp 
ON performance_metrics (tenant_id, timestamp DESC);

-- √çndices para business_metrics
CREATE INDEX IF NOT EXISTS idx_business_metrics_name_timestamp 
ON business_metrics (metric_name, timestamp DESC);

CREATE INDEX IF NOT EXISTS idx_business_metrics_type_timestamp 
ON business_metrics (metric_type, timestamp DESC);

CREATE INDEX IF NOT EXISTS idx_business_metrics_dimensions 
ON business_metrics USING GIN (dimensions);

-- √çndices para dashboards
CREATE INDEX IF NOT EXISTS idx_dashboards_tenant 
ON dashboards (tenant_id);

CREATE INDEX IF NOT EXISTS idx_dashboard_widgets_dashboard 
ON dashboard_widgets (dashboard_id);

-- √çndices para relat√≥rios
CREATE INDEX IF NOT EXISTS idx_reports_tenant 
ON reports (tenant_id);

CREATE INDEX IF NOT EXISTS idx_reports_next_run 
ON reports (next_run) WHERE is_active = TRUE;

-- √çndices para alertas
CREATE INDEX IF NOT EXISTS idx_alert_rules_tenant 
ON alert_rules (tenant_id) WHERE is_active = TRUE;

CREATE INDEX IF NOT EXISTS idx_alerts_status_created 
ON alerts (status, created_at DESC);

-- =====================================================
-- VIEWS MATERIALIZADAS PARA ANALYTICS
-- =====================================================

-- View para m√©tricas di√°rias agregadas
CREATE MATERIALIZED VIEW IF NOT EXISTS daily_metrics AS
SELECT 
    tenant_id,
    DATE_TRUNC('day', timestamp) as date,
    event_type,
    COUNT(*) as event_count,
    COUNT(DISTINCT user_id) as unique_users,
    COUNT(DISTINCT session_id) as unique_sessions,
    AVG(event_value) as avg_value
FROM system_events 
WHERE timestamp >= NOW() - INTERVAL '90 days'
GROUP BY tenant_id, DATE_TRUNC('day', timestamp), event_type;

-- √çndice para a view materializada
CREATE UNIQUE INDEX IF NOT EXISTS idx_daily_metrics_unique 
ON daily_metrics (tenant_id, date, event_type);

-- View para performance agregada por servi√ßo
CREATE MATERIALIZED VIEW IF NOT EXISTS service_performance AS
SELECT 
    tenant_id,
    service_name,
    DATE_TRUNC('hour', timestamp) as hour,
    AVG(response_time) as avg_response_time,
    MAX(response_time) as max_response_time,
    AVG(memory_usage) as avg_memory_usage,
    AVG(cpu_usage) as avg_cpu_usage,
    SUM(error_count) as total_errors,
    SUM(success_count) as total_success
FROM performance_metrics 
WHERE timestamp >= NOW() - INTERVAL '30 days'
GROUP BY tenant_id, service_name, DATE_TRUNC('hour', timestamp);

-- =====================================================
-- FUN√á√ïES PARA AGREGA√á√ÉO E AN√ÅLISE
-- =====================================================

-- Fun√ß√£o para calcular m√©tricas de engagement
CREATE OR REPLACE FUNCTION calculate_engagement_metrics(
    p_tenant_id UUID,
    p_start_date TIMESTAMPTZ,
    p_end_date TIMESTAMPTZ
) RETURNS JSONB AS $$
DECLARE
    result JSONB;
BEGIN
    SELECT jsonb_build_object(
        'total_events', COUNT(*),
        'unique_users', COUNT(DISTINCT user_id),
        'unique_sessions', COUNT(DISTINCT session_id),
        'avg_session_duration', AVG(
            EXTRACT(EPOCH FROM (
                MAX(timestamp) OVER (PARTITION BY session_id) - 
                MIN(timestamp) OVER (PARTITION BY session_id)
            ))
        ),
        'bounce_rate', (
            SELECT COUNT(DISTINCT session_id)::DECIMAL / 
                   COUNT(DISTINCT session_id) 
            FROM system_events se2 
            WHERE se2.tenant_id = p_tenant_id 
            AND se2.timestamp BETWEEN p_start_date AND p_end_date
            GROUP BY session_id
            HAVING COUNT(*) = 1
        ),
        'page_views', COUNT(*) FILTER (WHERE event_type = 'page_view'),
        'conversions', COUNT(*) FILTER (WHERE event_type = 'conversion')
    ) INTO result
    FROM system_events 
    WHERE tenant_id = p_tenant_id 
    AND timestamp BETWEEN p_start_date AND p_end_date;
    
    RETURN result;
END;
$$ LANGUAGE plpgsql;

-- Fun√ß√£o para detectar anomalias
CREATE OR REPLACE FUNCTION detect_anomalies(
    p_tenant_id UUID,
    p_metric_name VARCHAR,
    p_lookback_hours INTEGER DEFAULT 24
) RETURNS TABLE (
    timestamp TIMESTAMPTZ,
    value DECIMAL,
    expected_value DECIMAL,
    anomaly_score DECIMAL
) AS $$
BEGIN
    RETURN QUERY
    WITH metric_stats AS (
        SELECT 
            AVG(metric_value) as mean_value,
            STDDEV(metric_value) as std_value
        FROM business_metrics 
        WHERE tenant_id = p_tenant_id 
        AND metric_name = p_metric_name
        AND timestamp >= NOW() - INTERVAL '7 days'
    ),
    recent_metrics AS (
        SELECT 
            bm.timestamp,
            bm.metric_value,
            ms.mean_value,
            ms.std_value,
            ABS(bm.metric_value - ms.mean_value) / NULLIF(ms.std_value, 0) as z_score
        FROM business_metrics bm
        CROSS JOIN metric_stats ms
        WHERE bm.tenant_id = p_tenant_id 
        AND bm.metric_name = p_metric_name
        AND bm.timestamp >= NOW() - (p_lookback_hours || ' hours')::INTERVAL
    )
    SELECT 
        rm.timestamp,
        rm.metric_value,
        rm.mean_value,
        rm.z_score
    FROM recent_metrics rm
    WHERE rm.z_score > 2 -- Valores com z-score > 2 s√£o considerados anomalias
    ORDER BY rm.timestamp DESC;
END;
$$ LANGUAGE plpgsql;

-- =====================================================
-- TRIGGERS PARA AUTOMA√á√ÉO
-- =====================================================

-- Trigger para processamento autom√°tico de eventos
CREATE OR REPLACE FUNCTION process_system_event() 
RETURNS TRIGGER AS $$
BEGIN
    -- Atualizar estat√≠sticas em tempo real
    INSERT INTO business_metrics (
        tenant_id, metric_name, metric_type, metric_value, 
        dimensions, timestamp
    ) VALUES (
        NEW.tenant_id, 
        'event_' || NEW.event_type, 
        'counter', 
        1,
        jsonb_build_object(
            'event_category', NEW.event_category,
            'event_action', NEW.event_action,
            'device_type', NEW.device_type
        ),
        NEW.timestamp
    );
    
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_process_system_event
    AFTER INSERT ON system_events
    FOR EACH ROW EXECUTE FUNCTION process_system_event();

-- =====================================================
-- POLICIES DE SEGURAN√áA (RLS)
-- =====================================================

-- Habilitar RLS em todas as tabelas
ALTER TABLE system_events ENABLE ROW LEVEL SECURITY;
ALTER TABLE performance_metrics ENABLE ROW LEVEL SECURITY;
ALTER TABLE business_metrics ENABLE ROW LEVEL SECURITY;
ALTER TABLE dashboards ENABLE ROW LEVEL SECURITY;
ALTER TABLE dashboard_widgets ENABLE ROW LEVEL SECURITY;
ALTER TABLE reports ENABLE ROW LEVEL SECURITY;
ALTER TABLE alert_rules ENABLE ROW LEVEL SECURITY;
ALTER TABLE alerts ENABLE ROW LEVEL SECURITY;

-- Policies para isolamento por tenant
CREATE POLICY tenant_isolation_system_events ON system_events
    FOR ALL TO authenticated
    USING (tenant_id = auth.tenant_id());

CREATE POLICY tenant_isolation_performance_metrics ON performance_metrics
    FOR ALL TO authenticated
    USING (tenant_id = auth.tenant_id());

CREATE POLICY tenant_isolation_business_metrics ON business_metrics
    FOR ALL TO authenticated
    USING (tenant_id = auth.tenant_id());

CREATE POLICY tenant_isolation_dashboards ON dashboards
    FOR ALL TO authenticated
    USING (tenant_id = auth.tenant_id());

CREATE POLICY tenant_isolation_reports ON reports
    FOR ALL TO authenticated
    USING (tenant_id = auth.tenant_id());

CREATE POLICY tenant_isolation_alert_rules ON alert_rules
    FOR ALL TO authenticated
    USING (tenant_id = auth.tenant_id());

CREATE POLICY tenant_isolation_alerts ON alerts
    FOR ALL TO authenticated
    USING (tenant_id = auth.tenant_id());

-- =====================================================
-- CONFIGURA√á√ÉO DE COMPRESS√ÉO E RETEN√á√ÉO
-- =====================================================

-- Pol√≠ticas de compress√£o para TimescaleDB
SELECT add_compression_policy('system_events', INTERVAL '7 days');
SELECT add_compression_policy('performance_metrics', INTERVAL '1 day');
SELECT add_compression_policy('business_metrics', INTERVAL '7 days');

-- Pol√≠ticas de reten√ß√£o
SELECT add_retention_policy('system_events', INTERVAL '2 years');
SELECT add_retention_policy('performance_metrics', INTERVAL '6 months');
SELECT add_retention_policy('business_metrics', INTERVAL '1 year');

-- Refresh autom√°tico das views materializadas
SELECT add_continuous_aggregate_policy('daily_metrics',
    start_offset => INTERVAL '1 month',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour');

SELECT add_continuous_aggregate_policy('service_performance',
    start_offset => INTERVAL '1 week',
    end_offset => INTERVAL '10 minutes',
    schedule_interval => INTERVAL '10 minutes');

COMMIT;
```

## üîß Implementa√ß√£o dos Servi√ßos

### Analytics Service (Node.js/TypeScript)

```typescript
// src/services/analytics/analytics.service.ts

import { Injectable, Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';
import { Repository, Between, Raw } from 'typeorm';
import { InjectRedis } from '@liaoliaots/nestjs-redis';
import Redis from 'ioredis';
import { EventEmitter2 } from '@nestjs/event-emitter';
import { 
  SystemEvent, 
  PerformanceMetric, 
  BusinessMetric,
  Dashboard,
  Report,
  AlertRule,
  Alert 
} from './entities';
import { 
  TrackEventDto, 
  CreateDashboardDto, 
  QueryMetricsDto,
  CreateReportDto,
  CreateAlertRuleDto 
} from './dto';
import { AnalyticsGateway } from './analytics.gateway';
import { MLService } from '../ml/ml.service';

@Injectable()
export class AnalyticsService {
  private readonly logger = new Logger(AnalyticsService.name);

  constructor(
    @InjectRepository(SystemEvent)
    private systemEventRepository: Repository<SystemEvent>,
    
    @InjectRepository(PerformanceMetric)
    private performanceMetricRepository: Repository<PerformanceMetric>,
    
    @InjectRepository(BusinessMetric)
    private businessMetricRepository: Repository<BusinessMetric>,
    
    @InjectRepository(Dashboard)
    private dashboardRepository: Repository<Dashboard>,
    
    @InjectRepository(Report)
    private reportRepository: Repository<Report>,
    
    @InjectRepository(AlertRule)
    private alertRuleRepository: Repository<AlertRule>,
    
    @InjectRepository(Alert)
    private alertRepository: Repository<Alert>,
    
    @InjectRedis() private readonly redis: Redis,
    private readonly eventEmitter: EventEmitter2,
    private readonly analyticsGateway: AnalyticsGateway,
    private readonly mlService: MLService
  ) {}

  // =====================================================
  // COLETA DE EVENTOS
  // =====================================================

  async trackEvent(tenantId: string, dto: TrackEventDto): Promise<SystemEvent> {
    try {
      // Enriquecer dados do evento
      const enrichedEvent = await this.enrichEventData(dto);
      
      // Salvar evento
      const event = this.systemEventRepository.create({
        tenantId,
        ...enrichedEvent
      });
      
      const savedEvent = await this.systemEventRepository.save(event);
      
      // Cache para consultas r√°pidas
      await this.cacheEventMetrics(tenantId, savedEvent);
      
      // Processar em tempo real
      await this.processRealTimeEvent(savedEvent);
      
      // Emitir evento para WebSocket
      this.analyticsGateway.emitEventToTenant(tenantId, 'event_tracked', {
        id: savedEvent.id,
        type: savedEvent.eventType,
        timestamp: savedEvent.timestamp
      });
      
      this.logger.debug(`Event tracked: ${savedEvent.eventType} for tenant ${tenantId}`);
      
      return savedEvent;
    } catch (error) {
      this.logger.error(`Error tracking event: ${error.message}`, error.stack);
      throw error;
    }
  }

  async trackPerformanceMetric(
    tenantId: string, 
    serviceName: string, 
    metrics: Partial<PerformanceMetric>
  ): Promise<PerformanceMetric> {
    try {
      const metric = this.performanceMetricRepository.create({
        tenantId,
        serviceName,
        ...metrics
      });
      
      const savedMetric = await this.performanceMetricRepository.save(metric);
      
      // Verificar alertas de performance
      await this.checkPerformanceAlerts(tenantId, savedMetric);
      
      return savedMetric;
    } catch (error) {
      this.logger.error(`Error tracking performance metric: ${error.message}`);
      throw error;
    }
  }

  async trackBusinessMetric(
    tenantId: string,
    metricName: string,
    value: number,
    dimensions?: Record<string, any>,
    tags?: Record<string, any>
  ): Promise<BusinessMetric> {
    try {
      const metric = this.businessMetricRepository.create({
        tenantId,
        metricName,
        metricType: 'gauge',
        metricValue: value,
        dimensions,
        tags
      });
      
      const savedMetric = await this.businessMetricRepository.save(metric);
      
      // Detectar anomalias
      await this.detectAnomalies(tenantId, metricName, value);
      
      return savedMetric;
    } catch (error) {
      this.logger.error(`Error tracking business metric: ${error.message}`);
      throw error;
    }
  }

  // =====================================================
  // CONSULTAS E AN√ÅLISES
  // =====================================================

  async queryMetrics(tenantId: string, dto: QueryMetricsDto): Promise<any> {
    try {
      const { 
        metricType, 
        startDate, 
        endDate, 
        groupBy, 
        filters,
        aggregation = 'sum'
      } = dto;
      
      let query = this.businessMetricRepository
        .createQueryBuilder('metric')
        .where('metric.tenantId = :tenantId', { tenantId })
        .andWhere('metric.timestamp BETWEEN :startDate AND :endDate', {
          startDate,
          endDate
        });
      
      if (metricType) {
        query = query.andWhere('metric.metricName = :metricType', { metricType });
      }
      
      if (filters) {
        Object.entries(filters).forEach(([key, value]) => {
          query = query.andWhere(`metric.dimensions->>'${key}' = :${key}`, {
            [key]: value
          });
        });
      }
      
      if (groupBy) {
        switch (groupBy) {
          case 'hour':
            query = query
              .select("DATE_TRUNC('hour', metric.timestamp)", 'period')
              .addSelect(`${aggregation.toUpperCase()}(metric.metricValue)`, 'value')
              .groupBy("DATE_TRUNC('hour', metric.timestamp)")
              .orderBy('period', 'ASC');
            break;
          case 'day':
            query = query
              .select("DATE_TRUNC('day', metric.timestamp)", 'period')
              .addSelect(`${aggregation.toUpperCase()}(metric.metricValue)`, 'value')
              .groupBy("DATE_TRUNC('day', metric.timestamp)")
              .orderBy('period', 'ASC');
            break;
          case 'month':
            query = query
              .select("DATE_TRUNC('month', metric.timestamp)", 'period')
              .addSelect(`${aggregation.toUpperCase()}(metric.metricValue)`, 'value')
              .groupBy("DATE_TRUNC('month', metric.timestamp)")
              .orderBy('period', 'ASC');
            break;
        }
      }
      
      const results = await query.getRawMany();
      
      // Cache dos resultados por 5 minutos
      const cacheKey = `metrics:${tenantId}:${JSON.stringify(dto)}`;
      await this.redis.setex(cacheKey, 300, JSON.stringify(results));
      
      return results;
    } catch (error) {
      this.logger.error(`Error querying metrics: ${error.message}`);
      throw error;
    }
  }

  async getEngagementMetrics(
    tenantId: string, 
    startDate: Date, 
    endDate: Date
  ): Promise<any> {
    try {
      const cacheKey = `engagement:${tenantId}:${startDate.getTime()}:${endDate.getTime()}`;
      const cached = await this.redis.get(cacheKey);
      
      if (cached) {
        return JSON.parse(cached);
      }
      
      const result = await this.systemEventRepository.query(`
        SELECT calculate_engagement_metrics($1, $2, $3) as metrics
      `, [tenantId, startDate, endDate]);
      
      const metrics = result[0]?.metrics || {};
      
      // Cache por 10 minutos
      await this.redis.setex(cacheKey, 600, JSON.stringify(metrics));
      
      return metrics;
    } catch (error) {
      this.logger.error(`Error getting engagement metrics: ${error.message}`);
      throw error;
    }
  }

  async getFunnelAnalysis(
    tenantId: string,
    events: string[],
    startDate: Date,
    endDate: Date
  ): Promise<any> {
    try {
      const results = [];
      
      for (let i = 0; i < events.length; i++) {
        const eventType = events[i];
        
        // Usu√°rios que chegaram neste step
        const usersAtStep = await this.systemEventRepository
          .createQueryBuilder('event')
          .select('COUNT(DISTINCT event.userId)', 'count')
          .where('event.tenantId = :tenantId', { tenantId })
          .andWhere('event.eventType = :eventType', { eventType })
          .andWhere('event.timestamp BETWEEN :startDate AND :endDate', {
            startDate,
            endDate
          })
          .getRawOne();
        
        // Usu√°rios que completaram steps anteriores (se n√£o for o primeiro)
        let conversionRate = 100;
        if (i > 0) {
          const previousStepUsers = results[i - 1].users;
          conversionRate = previousStepUsers > 0 
            ? (parseInt(usersAtStep.count) / previousStepUsers) * 100 
            : 0;
        }
        
        results.push({
          step: i + 1,
          event: eventType,
          users: parseInt(usersAtStep.count),
          conversionRate: Math.round(conversionRate * 100) / 100,
          dropOffRate: Math.round((100 - conversionRate) * 100) / 100
        });
      }
      
      return results;
    } catch (error) {
      this.logger.error(`Error analyzing funnel: ${error.message}`);
      throw error;
    }
  }

  // =====================================================
  // DASHBOARDS
  // =====================================================

  async createDashboard(
    tenantId: string, 
    userId: string, 
    dto: CreateDashboardDto
  ): Promise<Dashboard> {
    try {
      const dashboard = this.dashboardRepository.create({
        tenantId,
        createdBy: userId,
        ...dto
      });
      
      const savedDashboard = await this.dashboardRepository.save(dashboard);
      
      // Invalidar cache de dashboards
      await this.redis.del(`dashboards:${tenantId}`);
      
      return savedDashboard;
    } catch (error) {
      this.logger.error(`Error creating dashboard: ${error.message}`);
      throw error;
    }
  }

  async getDashboards(tenantId: string): Promise<Dashboard[]> {
    try {
      const cacheKey = `dashboards:${tenantId}`;
      const cached = await this.redis.get(cacheKey);
      
      if (cached) {
        return JSON.parse(cached);
      }
      
      const dashboards = await this.dashboardRepository.find({
        where: { tenantId },
        order: { createdAt: 'DESC' }
      });
      
      // Cache por 15 minutos
      await this.redis.setex(cacheKey, 900, JSON.stringify(dashboards));
      
      return dashboards;
    } catch (error) {
      this.logger.error(`Error getting dashboards: ${error.message}`);
      throw error;
    }
  }

  async getDashboardData(
    tenantId: string, 
    dashboardId: string
  ): Promise<any> {
    try {
      const dashboard = await this.dashboardRepository.findOne({
        where: { id: dashboardId, tenantId },
        relations: ['widgets']
      });
      
      if (!dashboard) {
        throw new Error('Dashboard not found');
      }
      
      const widgetData = {};
      
      // Processar cada widget
      for (const widget of dashboard.widgets) {
        try {
          const data = await this.executeWidgetQuery(tenantId, widget);
          widgetData[widget.id] = data;
        } catch (error) {
          this.logger.error(`Error processing widget ${widget.id}: ${error.message}`);
          widgetData[widget.id] = { error: error.message };
        }
      }
      
      return {
        dashboard,
        data: widgetData
      };
    } catch (error) {
      this.logger.error(`Error getting dashboard data: ${error.message}`);
      throw error;
    }
  }

  // =====================================================
  // RELAT√ìRIOS
  // =====================================================

  async createReport(
    tenantId: string, 
    userId: string, 
    dto: CreateReportDto
  ): Promise<Report> {
    try {
      const report = this.reportRepository.create({
        tenantId,
        createdBy: userId,
        ...dto
      });
      
      // Calcular pr√≥xima execu√ß√£o se houver schedule
      if (dto.schedule) {
        report.nextRun = this.calculateNextRun(dto.schedule);
      }
      
      const savedReport = await this.reportRepository.save(report);
      
      return savedReport;
    } catch (error) {
      this.logger.error(`Error creating report: ${error.message}`);
      throw error;
    }
  }

  async generateReport(reportId: string): Promise<string> {
    try {
      const report = await this.reportRepository.findOne({
        where: { id: reportId }
      });
      
      if (!report) {
        throw new Error('Report not found');
      }
      
      // Executar query do relat√≥rio
      const data = await this.executeReportQuery(report.tenantId, report.query);
      
      // Gerar arquivo do relat√≥rio
      const filePath = await this.generateReportFile(report, data);
      
      // Atualizar registro de execu√ß√£o
      await this.reportRepository.update(reportId, {
        lastRun: new Date(),
        nextRun: this.calculateNextRun(report.schedule)
      });
      
      return filePath;
    } catch (error) {
      this.logger.error(`Error generating report: ${error.message}`);
      throw error;
    }
  }

  // =====================================================
  // ALERTAS
  // =====================================================

  async createAlertRule(
    tenantId: string, 
    userId: string, 
    dto: CreateAlertRuleDto
  ): Promise<AlertRule> {
    try {
      const alertRule = this.alertRuleRepository.create({
        tenantId,
        createdBy: userId,
        ...dto
      });
      
      const savedRule = await this.alertRuleRepository.save(alertRule);
      
      return savedRule;
    } catch (error) {
      this.logger.error(`Error creating alert rule: ${error.message}`);
      throw error;
    }
  }

  async checkAlerts(tenantId: string): Promise<void> {
    try {
      const activeRules = await this.alertRuleRepository.find({
        where: { tenantId, isActive: true }
      });
      
      for (const rule of activeRules) {
        await this.evaluateAlertRule(rule);
      }
    } catch (error) {
      this.logger.error(`Error checking alerts: ${error.message}`);
      throw error;
    }
  }

  // =====================================================
  // INTELIG√äNCIA ARTIFICIAL
  // =====================================================

  async generateInsights(tenantId: string): Promise<any> {
    try {
      // Coletar dados para an√°lise
      const recentMetrics = await this.getRecentMetricsForAI(tenantId);
      
      // Usar ML para gerar insights
      const insights = await this.mlService.generateInsights(recentMetrics);
      
      // Salvar insights no banco
      await this.saveInsights(tenantId, insights);
      
      return insights;
    } catch (error) {
      this.logger.error(`Error generating insights: ${error.message}`);
      throw error;
    }
  }

  async predictTrends(
    tenantId: string, 
    metricName: string, 
    daysAhead: number = 7
  ): Promise<any> {
    try {
      // Coletar dados hist√≥ricos
      const historicalData = await this.getHistoricalData(tenantId, metricName);
      
      // Usar ML para previs√£o
      const predictions = await this.mlService.predictTimeSeries(
        historicalData, 
        daysAhead
      );
      
      return predictions;
    } catch (error) {
      this.logger.error(`Error predicting trends: ${error.message}`);
      throw error;
    }
  }

  // =====================================================
  // M√âTODOS AUXILIARES
  // =====================================================

  private async enrichEventData(dto: TrackEventDto): Promise<any> {
    // Enriquecer com dados de geolocaliza√ß√£o, dispositivo, etc.
    const enriched = { ...dto };
    
    if (dto.ipAddress) {
      // Simular enriquecimento de geolocaliza√ß√£o
      enriched.locationCountry = 'BR';
      enriched.locationCity = 'S√£o Paulo';
    }
    
    if (dto.userAgent) {
      // Simular parsing do user agent
      enriched.browser = 'Chrome';
      enriched.platform = 'Web';
      enriched.deviceType = 'Desktop';
    }
    
    return enriched;
  }

  private async cacheEventMetrics(
    tenantId: string, 
    event: SystemEvent
  ): Promise<void> {
    const date = event.timestamp.toISOString().split('T')[0];
    const hourKey = `metrics:${tenantId}:${event.eventType}:${date}:${event.timestamp.getHours()}`;
    
    await this.redis.incr(hourKey);
    await this.redis.expire(hourKey, 86400); // 24 horas
  }

  private async processRealTimeEvent(event: SystemEvent): Promise<void> {
    // Processar evento em tempo real
    this.eventEmitter.emit('analytics.event.processed', event);
  }

  private async checkPerformanceAlerts(
    tenantId: string, 
    metric: PerformanceMetric
  ): Promise<void> {
    const rules = await this.alertRuleRepository.find({
      where: { 
        tenantId, 
        isActive: true,
        metricName: `performance_${metric.serviceName}_response_time`
      }
    });
    
    for (const rule of rules) {
      if (this.evaluateCondition(metric.responseTime, rule)) {
        await this.triggerAlert(rule, metric.responseTime);
      }
    }
  }

  private async detectAnomalies(
    tenantId: string, 
    metricName: string, 
    value: number
  ): Promise<void> {
    // Usar fun√ß√£o SQL para detectar anomalias
    const anomalies = await this.businessMetricRepository.query(`
      SELECT * FROM detect_anomalies($1, $2, 24)
    `, [tenantId, metricName]);
    
    if (anomalies.length > 0) {
      // Emitir alerta de anomalia
      this.analyticsGateway.emitEventToTenant(tenantId, 'anomaly_detected', {
        metric: metricName,
        value,
        anomalies
      });
    }
  }

  private async executeWidgetQuery(
    tenantId: string, 
    widget: any
  ): Promise<any> {
    // Implementar execu√ß√£o de consultas de widgets
    // Esta √© uma vers√£o simplificada
    return { data: [] };
  }

  private async executeReportQuery(
    tenantId: string, 
    query: any
  ): Promise<any> {
    // Implementar execu√ß√£o de consultas de relat√≥rios
    return [];
  }

  private async generateReportFile(
    report: Report, 
    data: any[]
  ): Promise<string> {
    // Implementar gera√ß√£o de arquivos de relat√≥rio (PDF, Excel, etc.)
    return `/reports/${report.id}_${Date.now()}.pdf`;
  }

  private calculateNextRun(schedule: any): Date {
    // Implementar c√°lculo da pr√≥xima execu√ß√£o baseado no cronograma
    return new Date(Date.now() + 24 * 60 * 60 * 1000); // +1 dia
  }

  private async evaluateAlertRule(rule: AlertRule): Promise<void> {
    // Implementar avalia√ß√£o de regras de alerta
    const currentValue = await this.getCurrentMetricValue(rule.metricName);
    
    if (this.evaluateCondition(currentValue, rule)) {
      await this.triggerAlert(rule, currentValue);
    }
  }

  private evaluateCondition(value: number, rule: AlertRule): boolean {
    switch (rule.comparisonOperator) {
      case '>':
        return value > rule.thresholdValue;
      case '<':
        return value < rule.thresholdValue;
      case '>=':
        return value >= rule.thresholdValue;
      case '<=':
        return value <= rule.thresholdValue;
      case '==':
        return value === rule.thresholdValue;
      default:
        return false;
    }
  }

  private async triggerAlert(rule: AlertRule, currentValue: number): Promise<void> {
    const alert = this.alertRepository.create({
      ruleId: rule.id,
      tenantId: rule.tenantId,
      currentValue,
      thresholdValue: rule.thresholdValue,
      message: `Alert: ${rule.name} - Current value ${currentValue} ${rule.comparisonOperator} ${rule.thresholdValue}`,
      severity: rule.severity
    });
    
    await this.alertRepository.save(alert);
    
    // Enviar notifica√ß√£o
    this.eventEmitter.emit('alert.triggered', { alert, rule });
  }

  private async getCurrentMetricValue(metricName: string): Promise<number> {
    const result = await this.businessMetricRepository
      .createQueryBuilder('metric')
      .select('AVG(metric.metricValue)', 'value')
      .where('metric.metricName = :metricName', { metricName })
      .andWhere('metric.timestamp >= :since', { 
        since: new Date(Date.now() - 60 * 60 * 1000) // √∫ltima hora
      })
      .getRawOne();
    
    return result?.value || 0;
  }

  private async getRecentMetricsForAI(tenantId: string): Promise<any> {
    // Coletar m√©tricas recentes para an√°lise de IA
    return {};
  }

  private async saveInsights(tenantId: string, insights: any): Promise<void> {
    // Salvar insights gerados pela IA
  }

  private async getHistoricalData(
    tenantId: string, 
    metricName: string
  ): Promise<any[]> {
    const data = await this.businessMetricRepository.find({
      where: { 
        tenantId, 
        metricName,
        timestamp: Raw(alias => `${alias} >= NOW() - INTERVAL '30 days'`)
      },
      order: { timestamp: 'ASC' }
    });
    
    return data.map(d => ({
      timestamp: d.timestamp,
      value: d.metricValue
    }));
  }
}
```

### Analytics Gateway (WebSocket)

```typescript
// src/services/analytics/analytics.gateway.ts

import {
  WebSocketGateway,
  WebSocketServer,
  SubscribeMessage,
  OnGatewayConnection,
  OnGatewayDisconnect,
  MessageBody,
  ConnectedSocket,
} from '@nestjs/websockets';
import { Server, Socket } from 'socket.io';
import { Logger, UseGuards } from '@nestjs/common';
import { JwtAuthGuard } from '../auth/guards/jwt-auth.guard';
import { TenantGuard } from '../tenant/guards/tenant.guard';
import { AnalyticsService } from './analytics.service';

@WebSocketGateway({
  namespace: 'analytics',
  cors: {
    origin: process.env.FRONTEND_URL || 'http://localhost:3000',
    credentials: true,
  },
})
@UseGuards(JwtAuthGuard, TenantGuard)
export class AnalyticsGateway implements OnGatewayConnection, OnGatewayDisconnect {
  @WebSocketServer()
  server: Server;

  private readonly logger = new Logger(AnalyticsGateway.name);
  private readonly clientRooms = new Map<string, Set<string>>();

  constructor(private readonly analyticsService: AnalyticsService) {}

  afterInit(server: Server) {
    this.logger.log('Analytics WebSocket Gateway initialized');
  }

  async handleConnection(client: Socket) {
    try {
      const user = client.handshake.auth.user;
      const tenantId = client.handshake.auth.tenantId;
      
      if (!user || !tenantId) {
        client.disconnect();
        return;
      }
      
      // Adicionar cliente √† sala do tenant
      const roomName = `tenant:${tenantId}`;
      client.join(roomName);
      
      // Rastrear salas do cliente
      if (!this.clientRooms.has(client.id)) {
        this.clientRooms.set(client.id, new Set());
      }
      this.clientRooms.get(client.id).add(roomName);
      
      this.logger.log(`Client ${client.id} connected to analytics for tenant ${tenantId}`);
      
      // Enviar dados iniciais
      await this.sendInitialData(client, tenantId);
      
    } catch (error) {
      this.logger.error(`Error handling connection: ${error.message}`);
      client.disconnect();
    }
  }

  async handleDisconnect(client: Socket) {
    const rooms = this.clientRooms.get(client.id);
    if (rooms) {
      rooms.forEach(room => {
        client.leave(room);
      });
      this.clientRooms.delete(client.id);
    }
    
    this.logger.log(`Client ${client.id} disconnected from analytics`);
  }

  @SubscribeMessage('subscribe_dashboard')
  async handleSubscribeDashboard(
    @ConnectedSocket() client: Socket,
    @MessageBody() data: { dashboardId: string }
  ) {
    try {
      const tenantId = client.handshake.auth.tenantId;
      const roomName = `dashboard:${data.dashboardId}`;
      
      client.join(roomName);
      this.clientRooms.get(client.id)?.add(roomName);
      
      // Enviar dados do dashboard
      const dashboardData = await this.analyticsService.getDashboardData(
        tenantId, 
        data.dashboardId
      );
      
      client.emit('dashboard_data', dashboardData);
      
    } catch (error) {
      client.emit('error', { message: error.message });
    }
  }

  @SubscribeMessage('subscribe_metrics')
  async handleSubscribeMetrics(
    @ConnectedSocket() client: Socket,
    @MessageBody() data: { metrics: string[] }
  ) {
    try {
      data.metrics.forEach(metric => {
        const roomName = `metric:${metric}`;
        client.join(roomName);
        this.clientRooms.get(client.id)?.add(roomName);
      });
      
      client.emit('metrics_subscribed', { metrics: data.metrics });
      
    } catch (error) {
      client.emit('error', { message: error.message });
    }
  }

  @SubscribeMessage('request_real_time_data')
  async handleRequestRealTimeData(
    @ConnectedSocket() client: Socket,
    @MessageBody() data: { type: string; config: any }
  ) {
    try {
      const tenantId = client.handshake.auth.tenantId;
      
      // Processar solicita√ß√£o de dados em tempo real
      const result = await this.processRealTimeRequest(tenantId, data);
      
      client.emit('real_time_data', result);
      
    } catch (error) {
      client.emit('error', { message: error.message });
    }
  }

  // =====================================================
  // M√âTODOS PARA EMISS√ÉO DE EVENTOS
  // =====================================================

  emitEventToTenant(tenantId: string, event: string, data: any) {
    this.server.to(`tenant:${tenantId}`).emit(event, data);
  }

  emitToDashboard(dashboardId: string, event: string, data: any) {
    this.server.to(`dashboard:${dashboardId}`).emit(event, data);
  }

  emitToMetricSubscribers(metric: string, data: any) {
    this.server.to(`metric:${metric}`).emit('metric_update', {
      metric,
      data
    });
  }

  emitAlert(tenantId: string, alert: any) {
    this.server.to(`tenant:${tenantId}`).emit('alert', alert);
  }

  // =====================================================
  // M√âTODOS AUXILIARES
  // =====================================================

  private async sendInitialData(client: Socket, tenantId: string) {
    try {
      // Enviar estat√≠sticas b√°sicas
      const stats = await this.getBasicStats(tenantId);
      client.emit('initial_stats', stats);
      
      // Enviar dashboards dispon√≠veis
      const dashboards = await this.analyticsService.getDashboards(tenantId);
      client.emit('available_dashboards', dashboards);
      
    } catch (error) {
      this.logger.error(`Error sending initial data: ${error.message}`);
    }
  }

  private async getBasicStats(tenantId: string): Promise<any> {
    const endDate = new Date();
    const startDate = new Date(endDate.getTime() - 24 * 60 * 60 * 1000); // 24h atr√°s
    
    return await this.analyticsService.getEngagementMetrics(
      tenantId, 
      startDate, 
      endDate
    );
  }

  private async processRealTimeRequest(
    tenantId: string, 
    request: any
  ): Promise<any> {
    // Processar diferentes tipos de solicita√ß√µes em tempo real
    switch (request.type) {
      case 'current_users':
        return await this.getCurrentActiveUsers(tenantId);
      case 'recent_events':
        return await this.getRecentEvents(tenantId);
      case 'performance_metrics':
        return await this.getCurrentPerformanceMetrics(tenantId);
      default:
        throw new Error(`Unknown request type: ${request.type}`);
    }
  }

  private async getCurrentActiveUsers(tenantId: string): Promise<number> {
    // Implementar contagem de usu√°rios ativos
    return 0;
  }

  private async getRecentEvents(tenantId: string): Promise<any[]> {
    // Implementar busca de eventos recentes
    return [];
  }

  private async getCurrentPerformanceMetrics(tenantId: string): Promise<any> {
    // Implementar m√©tricas de performance atuais
    return {};
  }
}
```

## üé® Componentes Frontend

### Dashboard Component

```typescript
// src/components/analytics/Dashboard.tsx

import React, { useState, useEffect, useCallback } from 'react';
import { 
  Grid, 
  Paper, 
  Typography, 
  Button, 
  IconButton,
  Menu,
  MenuItem,
  Dialog,
  DialogTitle,
  DialogContent,
  DialogActions,
  TextField,
  FormControl,
  InputLabel,
  Select,
  Chip,
  Fab,
  Tooltip
} from '@mui/material';
import {
  Add as AddIcon,
  Edit as EditIcon,
  Delete as DeleteIcon,
  Share as ShareIcon,
  Refresh as RefreshIcon,
  MoreVert as MoreIcon,
  Fullscreen as FullscreenIcon,
  Dashboard as DashboardIcon
} from '@mui/icons-material';
import { useTenant } from '../../hooks/useTenant';
import { useAnalytics } from '../../hooks/useAnalytics';
import { useWebSocket } from '../../hooks/useWebSocket';
import { WidgetContainer } from './widgets/WidgetContainer';
import { DashboardGrid } from './DashboardGrid';
import { WidgetLibrary } from './widgets/WidgetLibrary';
import { DashboardFilters } from './DashboardFilters';
import { toast } from 'react-toastify';

interface DashboardProps {
  dashboardId?: string;
  isEmbedded?: boolean;
  autoRefresh?: boolean;
}

interface Dashboard {
  id: string;
  name: string;
  description: string;
  config: any;
  layout: any;
  widgets: any[];
  filters: any;
  refreshInterval: number;
  isPublic: boolean;
}

interface Widget {
  id: string;
  type: string;
  title: string;
  config: any;
  query: any;
  position: { x: number; y: number };
  size: { w: number; h: number };
}

export const Dashboard: React.FC<DashboardProps> = ({
  dashboardId,
  isEmbedded = false,
  autoRefresh = true
}) => {
  const { tenant } = useTenant();
  const { analyticsService } = useAnalytics();
  const { socket, isConnected } = useWebSocket('analytics');

  // Estados
  const [dashboard, setDashboard] = useState<Dashboard | null>(null);
  const [widgets, setWidgets] = useState<Widget[]>([]);
  const [dashboardData, setDashboardData] = useState<Record<string, any>>({});
  const [loading, setLoading] = useState(true);
  const [editMode, setEditMode] = useState(false);
  const [selectedWidget, setSelectedWidget] = useState<Widget | null>(null);
  const [showWidgetLibrary, setShowWidgetLibrary] = useState(false);
  const [filters, setFilters] = useState<any>({});
  const [refreshing, setRefreshing] = useState(false);
  const [anchorEl, setAnchorEl] = useState<HTMLElement | null>(null);

  // Dialog states
  const [showEditDialog, setShowEditDialog] = useState(false);
  const [showShareDialog, setShowShareDialog] = useState(false);

  // =====================================================
  // EFFECTS
  // =====================================================

  useEffect(() => {
    if (dashboardId && tenant) {
      loadDashboard();
    }
  }, [dashboardId, tenant]);

  useEffect(() => {
    if (socket && isConnected && dashboardId) {
      // Subscrever a updates do dashboard
      socket.emit('subscribe_dashboard', { dashboardId });

      // Listeners de eventos
      socket.on('dashboard_data', handleDashboardData);
      socket.on('metric_update', handleMetricUpdate);
      socket.on('alert', handleAlert);

      return () => {
        socket.off('dashboard_data');
        socket.off('metric_update');
        socket.off('alert');
      };
    }
  }, [socket, isConnected, dashboardId]);

  useEffect(() => {
    if (autoRefresh && dashboard?.refreshInterval && !editMode) {
      const interval = setInterval(() => {
        refreshDashboard();
      }, dashboard.refreshInterval * 1000);

      return () => clearInterval(interval);
    }
  }, [dashboard, autoRefresh, editMode]);

  // =====================================================
  // HANDLERS DE DADOS
  // =====================================================

  const loadDashboard = async () => {
    try {
      setLoading(true);
      const data = await analyticsService.getDashboardData(dashboardId!);
      
      setDashboard(data.dashboard);
      setWidgets(data.dashboard.widgets || []);
      setDashboardData(data.data || {});
      
      if (data.dashboard.filters) {
        setFilters(data.dashboard.filters);
      }
    } catch (error) {
      console.error('Error loading dashboard:', error);
      toast.error('Erro ao carregar dashboard');
    } finally {
      setLoading(false);
    }
  };

  const refreshDashboard = async () => {
    if (refreshing || !dashboardId) return;
    
    try {
      setRefreshing(true);
      const data = await analyticsService.getDashboardData(dashboardId);
      setDashboardData(data.data || {});
    } catch (error) {
      console.error('Error refreshing dashboard:', error);
      toast.error('Erro ao atualizar dashboard');
    } finally {
      setRefreshing(false);
    }
  };

  const handleDashboardData = useCallback((data: any) => {
    setDashboardData(prevData => ({ ...prevData, ...data.data }));
  }, []);

  const handleMetricUpdate = useCallback((data: any) => {
    setDashboardData(prevData => ({
      ...prevData,
      [data.metric]: data.data
    }));
  }, []);

  const handleAlert = useCallback((alert: any) => {
    toast.warning(`Alerta: ${alert.message}`, {
      position: 'top-right',
      autoClose: 10000
    });
  }, []);

  // =====================================================
  // HANDLERS DE EDI√á√ÉO
  // =====================================================

  const handleAddWidget = async (widgetConfig: any) => {
    try {
      const newWidget: Widget = {
        id: `widget_${Date.now()}`,
        type: widgetConfig.type,
        title: widgetConfig.title,
        config: widgetConfig.config,
        query: widgetConfig.query,
        position: { x: 0, y: 0 },
        size: widgetConfig.defaultSize || { w: 4, h: 3 }
      };

      const updatedWidgets = [...widgets, newWidget];
      setWidgets(updatedWidgets);

      // Salvar no backend
      await saveDashboard({ widgets: updatedWidgets });
      
      toast.success('Widget adicionado com sucesso');
    } catch (error) {
      console.error('Error adding widget:', error);
      toast.error('Erro ao adicionar widget');
    }
  };

  const handleUpdateWidget = async (widgetId: string, updates: Partial<Widget>) => {
    try {
      const updatedWidgets = widgets.map(widget =>
        widget.id === widgetId ? { ...widget, ...updates } : widget
      );
      
      setWidgets(updatedWidgets);
      
      // Salvar no backend
      await saveDashboard({ widgets: updatedWidgets });
    } catch (error) {
      console.error('Error updating widget:', error);
      toast.error('Erro ao atualizar widget');
    }
  };

  const handleDeleteWidget = async (widgetId: string) => {
    try {
      const updatedWidgets = widgets.filter(widget => widget.id !== widgetId);
      setWidgets(updatedWidgets);
      
      // Salvar no backend
      await saveDashboard({ widgets: updatedWidgets });
      
      toast.success('Widget removido com sucesso');
    } catch (error) {
      console.error('Error deleting widget:', error);
      toast.error('Erro ao remover widget');
    }
  };

  const handleLayoutChange = async (layout: any[]) => {
    try {
      const updatedWidgets = widgets.map(widget => {
        const layoutItem = layout.find(item => item.i === widget.id);
        if (layoutItem) {
          return {
            ...widget,
            position: { x: layoutItem.x, y: layoutItem.y },
            size: { w: layoutItem.w, h: layoutItem.h }
          };
        }
        return widget;
      });
      
      setWidgets(updatedWidgets);
      
      // Salvar no backend (com debounce)
      await saveDashboard({ widgets: updatedWidgets });
    } catch (error) {
      console.error('Error saving layout:', error);
    }
  };

  const saveDashboard = async (updates: Partial<Dashboard>) => {
    if (!dashboard) return;
    
    try {
      await analyticsService.updateDashboard(dashboard.id, updates);
      setDashboard(prev => prev ? { ...prev, ...updates } : null);
    } catch (error) {
      console.error('Error saving dashboard:', error);
      throw error;
    }
  };

  // =====================================================
  // HANDLERS DE FILTROS
  // =====================================================

  const handleFiltersChange = async (newFilters: any) => {
    setFilters(newFilters);
    
    // Aplicar filtros e recarregar dados
    if (dashboardId) {
      const data = await analyticsService.getDashboardData(dashboardId, newFilters);
      setDashboardData(data.data || {});
    }
  };

  // =====================================================
  // HANDLERS DE UI
  // =====================================================

  const handleMenuOpen = (event: React.MouseEvent<HTMLElement>) => {
    setAnchorEl(event.currentTarget);
  };

  const handleMenuClose = () => {
    setAnchorEl(null);
  };

  const handleToggleEditMode = () => {
    setEditMode(!editMode);
    setSelectedWidget(null);
  };

  const handleShareDashboard = async () => {
    try {
      const shareUrl = `${window.location.origin}/shared/dashboard/${dashboard?.id}`;
      await navigator.clipboard.writeText(shareUrl);
      toast.success('Link copiado para a √°rea de transfer√™ncia');
      setShowShareDialog(false);
    } catch (error) {
      toast.error('Erro ao copiar link');
    }
  };

  // =====================================================
  // RENDER
  // =====================================================

  if (loading) {
    return (
      <div className="dashboard-loading">
        <div className="loading-spinner">
          <DashboardIcon className="loading-icon" />
          <Typography variant="h6">Carregando dashboard...</Typography>
        </div>
      </div>
    );
  }

  if (!dashboard) {
    return (
      <div className="dashboard-error">
        <Typography variant="h6">Dashboard n√£o encontrado</Typography>
      </div>
    );
  }

  return (
    <div className={`analytics-dashboard ${editMode ? 'edit-mode' : ''}`}>
      {/* Header */}
      {!isEmbedded && (
        <div className="dashboard-header">
          <div className="dashboard-title">
            <Typography variant="h4" component="h1">
              {dashboard.name}
            </Typography>
            {dashboard.description && (
              <Typography variant="subtitle1" color="textSecondary">
                {dashboard.description}
              </Typography>
            )}
          </div>

          <div className="dashboard-actions">
            {/* Status de conex√£o */}
            <Chip
              label={isConnected ? 'Online' : 'Offline'}
              color={isConnected ? 'success' : 'error'}
              size="small"
              variant="outlined"
            />

            {/* Bot√£o de refresh */}
            <Tooltip title="Atualizar dados">
              <IconButton 
                onClick={refreshDashboard}
                disabled={refreshing}
                className={refreshing ? 'rotating' : ''}
              >
                <RefreshIcon />
              </IconButton>
            </Tooltip>

            {/* Bot√£o de edi√ß√£o */}
            <Button
              variant={editMode ? 'contained' : 'outlined'}
              startIcon={<EditIcon />}
              onClick={handleToggleEditMode}
            >
              {editMode ? 'Finalizar Edi√ß√£o' : 'Editar'}
            </Button>

            {/* Menu de op√ß√µes */}
            <IconButton onClick={handleMenuOpen}>
              <MoreIcon />
            </IconButton>
            
            <Menu
              anchorEl={anchorEl}
              open={Boolean(anchorEl)}
              onClose={handleMenuClose}
            >
              <MenuItem onClick={() => { setShowShareDialog(true); handleMenuClose(); }}>
                <ShareIcon sx={{ mr: 1 }} />
                Compartilhar
              </MenuItem>
              <MenuItem onClick={() => { setShowEditDialog(true); handleMenuClose(); }}>
                <EditIcon sx={{ mr: 1 }} />
                Configura√ß√µes
              </MenuItem>
              <MenuItem onClick={handleMenuClose}>
                <FullscreenIcon sx={{ mr: 1 }} />
                Tela Cheia
              </MenuItem>
            </Menu>
          </div>
        </div>
      )}

      {/* Filtros */}
      {dashboard.filters && (
        <DashboardFilters
          filters={dashboard.filters}
          values={filters}
          onChange={handleFiltersChange}
        />
      )}

      {/* Grid de Widgets */}
      <DashboardGrid
        widgets={widgets}
        data={dashboardData}
        editMode={editMode}
        onLayoutChange={handleLayoutChange}
        onWidgetSelect={setSelectedWidget}
        onWidgetUpdate={handleUpdateWidget}
        onWidgetDelete={handleDeleteWidget}
      />

      {/* Bot√£o de adicionar widget */}
      {editMode && (
        <Fab
          color="primary"
          className="add-widget-fab"
          onClick={() => setShowWidgetLibrary(true)}
        >
          <AddIcon />
        </Fab>
      )}

      {/* Widget Library Dialog */}
      <WidgetLibrary
        open={showWidgetLibrary}
        onClose={() => setShowWidgetLibrary(false)}
        onAddWidget={handleAddWidget}
      />

      {/* Share Dialog */}
      <Dialog
        open={showShareDialog}
        onClose={() => setShowShareDialog(false)}
        maxWidth="sm"
        fullWidth
      >
        <DialogTitle>Compartilhar Dashboard</DialogTitle>
        <DialogContent>
          <Typography variant="body2" gutterBottom>
            Link p√∫blico para compartilhar este dashboard:
          </Typography>
          <TextField
            fullWidth
            value={`${window.location.origin}/shared/dashboard/${dashboard.id}`}
            InputProps={{ readOnly: true }}
            variant="outlined"
            size="small"
          />
        </DialogContent>
        <DialogActions>
          <Button onClick={() => setShowShareDialog(false)}>
            Cancelar
          </Button>
          <Button onClick={handleShareDashboard} variant="contained">
            Copiar Link
          </Button>
        </DialogActions>
      </Dialog>
    </div>
  );
};

export default Dashboard;
```

### Analytics Hook

```typescript
// src/hooks/useAnalytics.ts

import { useState, useEffect, useCallback } from 'react';
import { useWebSocket } from './useWebSocket';
import { useTenant } from './useTenant';
import { analyticsApi } from '../api/analytics';

interface AnalyticsHook {
  trackEvent: (event: any) => Promise<void>;
  trackPageView: (page: string) => Promise<void>;
  trackConversion: (type: string, value?: number) => Promise<void>;
  getDashboards: () => Promise<any[]>;
  createDashboard: (dashboard: any) => Promise<any>;
  updateDashboard: (id: string, updates: any) => Promise<any>;
  deleteDashboard: (id: string) => Promise<void>;
  queryMetrics: (query: any) => Promise<any>;
  generateReport: (reportId: string) => Promise<string>;
  getInsights: () => Promise<any[]>;
  isTracking: boolean;
  metrics: any;
  insights: any[];
}

export const useAnalytics = (): AnalyticsHook => {
  const { tenant } = useTenant();
  const { socket } = useWebSocket('analytics');
  
  const [isTracking, setIsTracking] = useState(false);
  const [metrics, setMetrics] = useState<any>({});
  const [insights, setInsights] = useState<any[]>([]);

  // =====================================================
  // TRACKING DE EVENTOS
  // =====================================================

  const trackEvent = useCallback(async (eventData: any) => {
    if (!tenant) return;
    
    try {
      setIsTracking(true);
      
      const enrichedEvent = {
        ...eventData,
        timestamp: new Date().toISOString(),
        sessionId: getSessionId(),
        userId: getCurrentUserId(),
        pageUrl: window.location.href,
        referrer: document.referrer,
        userAgent: navigator.userAgent
      };
      
      await analyticsApi.trackEvent(enrichedEvent);
      
      // Emitir via WebSocket para tracking em tempo real
      if (socket) {
        socket.emit('track_event', enrichedEvent);
      }
      
    } catch (error) {
      console.error('Error tracking event:', error);
    } finally {
      setIsTracking(false);
    }
  }, [tenant, socket]);

  const trackPageView = useCallback(async (page: string) => {
    await trackEvent({
      eventType: 'page_view',
      eventCategory: 'navigation',
      eventAction: 'view',
      eventLabel: page,
      properties: {
        page,
        title: document.title
      }
    });
  }, [trackEvent]);

  const trackConversion = useCallback(async (type: string, value?: number) => {
    await trackEvent({
      eventType: 'conversion',
      eventCategory: 'business',
      eventAction: type,
      eventValue: value,
      properties: {
        conversionType: type
      }
    });
  }, [trackEvent]);

  // =====================================================
  // DASHBOARDS
  // =====================================================

  const getDashboards = useCallback(async () => {
    if (!tenant) return [];
    
    try {
      return await analyticsApi.getDashboards();
    } catch (error) {
      console.error('Error getting dashboards:', error);
      return [];
    }
  }, [tenant]);

  const createDashboard = useCallback(async (dashboardData: any) => {
    if (!tenant) throw new Error('No tenant selected');
    
    try {
      const dashboard = await analyticsApi.createDashboard(dashboardData);
      return dashboard;
    } catch (error) {
      console.error('Error creating dashboard:', error);
      throw error;
    }
  }, [tenant]);

  const updateDashboard = useCallback(async (id: string, updates: any) => {
    if (!tenant) throw new Error('No tenant selected');
    
    try {
      const dashboard = await analyticsApi.updateDashboard(id, updates);
      return dashboard;
    } catch (error) {
      console.error('Error updating dashboard:', error);
      throw error;
    }
  }, [tenant]);

  const deleteDashboard = useCallback(async (id: string) => {
    if (!tenant) throw new Error('No tenant selected');
    
    try {
      await analyticsApi.deleteDashboard(id);
    } catch (error) {
      console.error('Error deleting dashboard:', error);
      throw error;
    }
  }, [tenant]);

  // =====================================================
  // CONSULTAS E M√âTRICAS
  // =====================================================

  const queryMetrics = useCallback(async (query: any) => {
    if (!tenant) return [];
    
    try {
      return await analyticsApi.queryMetrics(query);
    } catch (error) {
      console.error('Error querying metrics:', error);
      return [];
    }
  }, [tenant]);

  const generateReport = useCallback(async (reportId: string) => {
    if (!tenant) throw new Error('No tenant selected');
    
    try {
      return await analyticsApi.generateReport(reportId);
    } catch (error) {
      console.error('Error generating report:', error);
      throw error;
    }
  }, [tenant]);

  const getInsights = useCallback(async () => {
    if (!tenant) return [];
    
    try {
      const insights = await analyticsApi.getInsights();
      setInsights(insights);
      return insights;
    } catch (error) {
      console.error('Error getting insights:', error);
      return [];
    }
  }, [tenant]);

  // =====================================================
  // EFFECTS E LISTENERS
  // =====================================================

  useEffect(() => {
    if (socket) {
      socket.on('metric_update', (data: any) => {
        setMetrics(prev => ({
          ...prev,
          [data.metric]: data.value
        }));
      });

      socket.on('insight_generated', (insight: any) => {
        setInsights(prev => [insight, ...prev]);
      });

      return () => {
        socket.off('metric_update');
        socket.off('insight_generated');
      };
    }
  }, [socket]);

  // Auto-tracking de page views
  useEffect(() => {
    const handleRouteChange = () => {
      trackPageView(window.location.pathname);
    };

    // Track inicial
    trackPageView(window.location.pathname);

    // Listener para mudan√ßas de rota (SPA)
    window.addEventListener('popstate', handleRouteChange);
    
    return () => {
      window.removeEventListener('popstate', handleRouteChange);
    };
  }, [trackPageView]);

  // =====================================================
  // HELPERS
  // =====================================================

  const getSessionId = (): string => {
    let sessionId = sessionStorage.getItem('analytics_session_id');
    if (!sessionId) {
      sessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      sessionStorage.setItem('analytics_session_id', sessionId);
    }
    return sessionId;
  };

  const getCurrentUserId = (): string | null => {
    // Implementar obten√ß√£o do ID do usu√°rio atual
    return localStorage.getItem('user_id');
  };

  return {
    trackEvent,
    trackPageView,
    trackConversion,
    getDashboards,
    createDashboard,
    updateDashboard,
    deleteDashboard,
    queryMetrics,
    generateReport,
    getInsights,
    isTracking,
    metrics,
    insights
  };
};
```

## üöÄ Script de Configura√ß√£o

```bash
#!/bin/bash

# ==================================================
# KRYONIX ANALYTICS & BI - SCRIPT DE CONFIGURA√á√ÉO
# ==================================================

set -e

echo "üöÄ Iniciando configura√ß√£o do sistema de Analytics e BI..."

# Vari√°veis
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
ENV_FILE="$PROJECT_ROOT/.env"

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fun√ß√µes auxiliares
log_info() {
    echo -e "${BLUE}‚ÑπÔ∏è  $1${NC}"
}

log_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

log_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

log_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

# Verificar depend√™ncias
check_dependencies() {
    log_info "Verificando depend√™ncias..."
    
    command -v docker >/dev/null 2>&1 || { log_error "Docker n√£o est√° instalado"; exit 1; }
    command -v docker-compose >/dev/null 2>&1 || { log_error "Docker Compose n√£o est√° instalado"; exit 1; }
    command -v node >/dev/null 2>&1 || { log_error "Node.js n√£o est√° instalado"; exit 1; }
    command -v npm >/dev/null 2>&1 || { log_error "NPM n√£o est√° instalado"; exit 1; }
    
    log_success "Todas as depend√™ncias est√£o instaladas"
}

# Configurar vari√°veis de ambiente
setup_environment() {
    log_info "Configurando vari√°veis de ambiente..."
    
    # Analytics espec√≠ficas
    cat >> "$ENV_FILE" << EOL

# =====================================================
# ANALYTICS & BI CONFIGURATION
# =====================================================

# TimescaleDB
TIMESCALEDB_HOST=timescaledb
TIMESCALEDB_PORT=5432
TIMESCALEDB_USER=kryonix_analytics
TIMESCALEDB_PASSWORD=\${POSTGRES_PASSWORD}
TIMESCALEDB_DATABASE=kryonix_analytics

# ClickHouse
CLICKHOUSE_HOST=clickhouse
CLICKHOUSE_PORT=8123
CLICKHOUSE_USER=kryonix_analytics
CLICKHOUSE_PASSWORD=\${POSTGRES_PASSWORD}
CLICKHOUSE_DATABASE=kryonix_analytics

# Elasticsearch
ELASTICSEARCH_HOST=elasticsearch
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_USERNAME=elastic
ELASTICSEARCH_PASSWORD=\${POSTGRES_PASSWORD}

# Analytics Service
ANALYTICS_PORT=3010
ANALYTICS_RETENTION_DAYS=365
ANALYTICS_BATCH_SIZE=1000
ANALYTICS_REAL_TIME=true

# Machine Learning
ML_SERVICE_HOST=ml-service
ML_SERVICE_PORT=8080
ML_MODEL_PATH=/app/models
ML_TRAINING_ENABLED=true

# Reporting
REPORT_STORAGE_PATH=/app/reports
REPORT_MAX_SIZE=100MB
REPORT_FORMATS=PDF,EXCEL,CSV
REPORT_QUEUE_SIZE=100

# Alerts
ALERT_EMAIL_ENABLED=true
ALERT_SLACK_ENABLED=true
ALERT_WEBHOOK_ENABLED=true
ALERT_SMS_ENABLED=false

# Performance
ANALYTICS_WORKERS=4
ANALYTICS_QUEUE_SIZE=10000
ANALYTICS_CACHE_TTL=300

EOL

    log_success "Vari√°veis de ambiente configuradas"
}

# Configurar TimescaleDB
setup_timescaledb() {
    log_info "Configurando TimescaleDB..."
    
    cat > "$PROJECT_ROOT/docker/timescaledb/Dockerfile" << 'EOL'
FROM timescale/timescaledb:latest-pg14

# Instalar extens√µes adicionais
RUN apt-get update && apt-get install -y \
    postgresql-14-postgis-3 \
    postgresql-14-postgis-3-scripts \
    && rm -rf /var/lib/apt/lists/*

# Configura√ß√µes personalizadas
COPY postgresql.conf /etc/postgresql/postgresql.conf
COPY pg_hba.conf /etc/postgresql/pg_hba.conf

# Scripts de inicializa√ß√£o
COPY init-scripts/ /docker-entrypoint-initdb.d/

EXPOSE 5432
EOL

    # Configura√ß√£o do PostgreSQL otimizada para analytics
    cat > "$PROJECT_ROOT/docker/timescaledb/postgresql.conf" << 'EOL'
# TimescaleDB Configuration for Analytics

# Memory Settings
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 64MB
maintenance_work_mem = 256MB

# Checkpoint Settings
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100

# Parallel Query Settings
max_parallel_workers = 4
max_parallel_workers_per_gather = 2
max_parallel_maintenance_workers = 2

# TimescaleDB Specific
timescaledb.max_background_workers = 8
timescaledb.telemetry_level = off

# Logging
log_statement = 'mod'
log_min_duration_statement = 1000
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on

# Performance
random_page_cost = 1.1
effective_io_concurrency = 200
EOL

    mkdir -p "$PROJECT_ROOT/docker/timescaledb/init-scripts"
    
    # Script de inicializa√ß√£o
    cat > "$PROJECT_ROOT/docker/timescaledb/init-scripts/01-create-analytics-db.sql" << 'EOL'
-- Criar database para analytics
CREATE DATABASE kryonix_analytics;

-- Conectar ao database
\c kryonix_analytics;

-- Instalar extens√µes
CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE;
CREATE EXTENSION IF NOT EXISTS postgis;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- Criar usu√°rio para analytics
CREATE USER kryonix_analytics WITH PASSWORD 'analytics_password_123';
GRANT ALL PRIVILEGES ON DATABASE kryonix_analytics TO kryonix_analytics;
GRANT ALL ON SCHEMA public TO kryonix_analytics;
EOL

    log_success "TimescaleDB configurado"
}

# Configurar ClickHouse
setup_clickhouse() {
    log_info "Configurando ClickHouse..."
    
    mkdir -p "$PROJECT_ROOT/docker/clickhouse"
    
    cat > "$PROJECT_ROOT/docker/clickhouse/Dockerfile" << 'EOL'
FROM clickhouse/clickhouse-server:latest

# Configura√ß√µes personalizadas
COPY config.xml /etc/clickhouse-server/config.xml
COPY users.xml /etc/clickhouse-server/users.xml

# Scripts de inicializa√ß√£o
COPY init-scripts/ /docker-entrypoint-initdb.d/

EXPOSE 8123 9000
EOL

    # Configura√ß√£o do ClickHouse
    cat > "$PROJECT_ROOT/docker/clickhouse/config.xml" << 'EOL'
<?xml version="1.0"?>
<yandex>
    <logger>
        <level>information</level>
        <console>true</console>
    </logger>

    <http_port>8123</http_port>
    <tcp_port>9000</tcp_port>

    <listen_host>::</listen_host>

    <max_connections>4096</max_connections>
    <keep_alive_timeout>3</keep_alive_timeout>
    <max_concurrent_queries>100</max_concurrent_queries>

    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
    <mark_cache_size>5368709120</mark_cache_size>

    <path>/var/lib/clickhouse/</path>
    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>

    <users_config>users.xml</users_config>
    <default_profile>default</default_profile>
    <default_database>default</default_database>

    <timezone>America/Sao_Paulo</timezone>
</yandex>
EOL

    # Configura√ß√£o de usu√°rios
    cat > "$PROJECT_ROOT/docker/clickhouse/users.xml" << 'EOL'
<?xml version="1.0"?>
<yandex>
    <profiles>
        <default>
            <max_memory_usage>10000000000</max_memory_usage>
            <use_uncompressed_cache>0</use_uncompressed_cache>
            <load_balancing>random</load_balancing>
        </default>
    </profiles>

    <users>
        <default>
            <password></password>
            <networks incl="networks_config"/>
            <profile>default</profile>
            <quota>default</quota>
        </default>
        
        <kryonix_analytics>
            <password>analytics_password_123</password>
            <networks>
                <ip>::/0</ip>
            </networks>
            <profile>default</profile>
            <quota>default</quota>
        </kryonix_analytics>
    </users>

    <quotas>
        <default>
            <interval>
                <duration>3600</duration>
                <queries>0</queries>
                <errors>0</errors>
                <result_rows>0</result_rows>
                <read_rows>0</read_rows>
                <execution_time>0</execution_time>
            </interval>
        </default>
    </quotas>
</yandex>
EOL

    mkdir -p "$PROJECT_ROOT/docker/clickhouse/init-scripts"
    
    cat > "$PROJECT_ROOT/docker/clickhouse/init-scripts/01-create-tables.sql" << 'EOL'
-- Criar database para analytics
CREATE DATABASE IF NOT EXISTS kryonix_analytics;

-- Usar database
USE kryonix_analytics;

-- Tabela para eventos agregados
CREATE TABLE IF NOT EXISTS events_hourly (
    tenant_id String,
    event_type String,
    date Date,
    hour UInt8,
    events_count UInt64,
    unique_users UInt64,
    total_value Float64
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (tenant_id, event_type, date, hour);

-- Tabela para m√©tricas de performance
CREATE TABLE IF NOT EXISTS performance_hourly (
    tenant_id String,
    service_name String,
    date Date,
    hour UInt8,
    avg_response_time Float64,
    max_response_time Float64,
    total_requests UInt64,
    error_count UInt64
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (tenant_id, service_name, date, hour);
EOL

    log_success "ClickHouse configurado"
}

# Configurar Elasticsearch
setup_elasticsearch() {
    log_info "Configurando Elasticsearch..."
    
    mkdir -p "$PROJECT_ROOT/docker/elasticsearch"
    
    cat > "$PROJECT_ROOT/docker/elasticsearch/Dockerfile" << 'EOL'
FROM docker.elastic.co/elasticsearch/elasticsearch:8.10.0

# Plugins adicionais
RUN elasticsearch-plugin install analysis-icu
RUN elasticsearch-plugin install analysis-phonetic

# Configura√ß√µes personalizadas
COPY elasticsearch.yml /usr/share/elasticsearch/config/elasticsearch.yml

EXPOSE 9200 9300
EOL

    # Configura√ß√£o do Elasticsearch
    cat > "$PROJECT_ROOT/docker/elasticsearch/elasticsearch.yml" << 'EOL'
cluster.name: kryonix-analytics
node.name: elasticsearch-analytics
path.data: /usr/share/elasticsearch/data
path.logs: /usr/share/elasticsearch/logs
network.host: 0.0.0.0
http.port: 9200
transport.port: 9300

# Security
xpack.security.enabled: true
xpack.security.enrollment.enabled: false
xpack.security.http.ssl.enabled: false
xpack.security.transport.ssl.enabled: false

# Performance
bootstrap.memory_lock: true
indices.memory.index_buffer_size: 30%
indices.queries.cache.size: 20%

# Machine Learning
xpack.ml.enabled: true
EOL

    log_success "Elasticsearch configurado"
}

# Instalar depend√™ncias NPM
install_dependencies() {
    log_info "Instalando depend√™ncias do Analytics..."
    
    cd "$PROJECT_ROOT"
    
    # Analytics espec√≠ficas
    npm install --save \
        @nestjs/typeorm \
        typeorm \
        pg \
        @types/pg \
        timescaledb \
        clickhouse \
        @elastic/elasticsearch \
        ioredis \
        bull \
        @nestjs/bull \
        cron \
        node-cron \
        puppeteer \
        exceljs \
        pdfkit \
        chart.js \
        d3 \
        react-grid-layout \
        recharts \
        @mui/x-charts \
        socket.io-client \
        date-fns \
        lodash \
        uuid \
        joi \
        class-validator \
        class-transformer
    
    # Dev dependencies
    npm install --save-dev \
        @types/lodash \
        @types/uuid \
        @types/node-cron \
        @types/puppeteer
    
    log_success "Depend√™ncias instaladas"
}

# Configurar Docker Compose
setup_docker_compose() {
    log_info "Configurando servi√ßos Docker..."
    
    cat >> "$PROJECT_ROOT/docker-compose.yml" << 'EOL'

  # =====================================================
  # ANALYTICS & BI SERVICES
  # =====================================================

  timescaledb:
    build: 
      context: ./docker/timescaledb
      dockerfile: Dockerfile
    container_name: kryonix-timescaledb
    restart: unless-stopped
    environment:
      POSTGRES_DB: kryonix_analytics
      POSTGRES_USER: kryonix_analytics
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      TIMESCALEDB_TELEMETRY: off
    volumes:
      - timescaledb_data:/var/lib/postgresql/data
      - ./backups/timescaledb:/backups
    ports:
      - "5433:5432"
    networks:
      - kryonix_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U kryonix_analytics -d kryonix_analytics"]
      interval: 30s
      timeout: 10s
      retries: 5

  clickhouse:
    build:
      context: ./docker/clickhouse
      dockerfile: Dockerfile
    container_name: kryonix-clickhouse
    restart: unless-stopped
    environment:
      CLICKHOUSE_DB: kryonix_analytics
      CLICKHOUSE_USER: kryonix_analytics
      CLICKHOUSE_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./backups/clickhouse:/backups
    ports:
      - "8123:8123"
      - "9000:9000"
    networks:
      - kryonix_network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8123/ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  elasticsearch:
    build:
      context: ./docker/elasticsearch
      dockerfile: Dockerfile
    container_name: kryonix-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - ELASTIC_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./backups/elasticsearch:/backups
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - kryonix_network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  analytics-service:
    build:
      context: .
      dockerfile: docker/analytics/Dockerfile
    container_name: kryonix-analytics
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: ${ANALYTICS_PORT}
      DATABASE_URL: postgresql://${TIMESCALEDB_USER}:${TIMESCALEDB_PASSWORD}@timescaledb:5432/${TIMESCALEDB_DATABASE}
      CLICKHOUSE_URL: http://${CLICKHOUSE_USER}:${CLICKHOUSE_PASSWORD}@clickhouse:8123/${CLICKHOUSE_DATABASE}
      ELASTICSEARCH_URL: http://elastic:${ELASTICSEARCH_PASSWORD}@elasticsearch:9200
      REDIS_URL: redis://redis:6379
    volumes:
      - ./logs/analytics:/app/logs
      - ./reports:/app/reports
      - ./uploads:/app/uploads
    ports:
      - "${ANALYTICS_PORT}:${ANALYTICS_PORT}"
    networks:
      - kryonix_network
    depends_on:
      - timescaledb
      - clickhouse
      - elasticsearch
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${ANALYTICS_PORT}/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  ml-service:
    build:
      context: ./docker/ml-service
      dockerfile: Dockerfile
    container_name: kryonix-ml
    restart: unless-stopped
    environment:
      PYTHON_ENV: production
      MODEL_PATH: /app/models
      DATA_PATH: /app/data
    volumes:
      - ./ml-models:/app/models
      - ./ml-data:/app/data
      - ./logs/ml:/app/logs
    ports:
      - "8080:8080"
    networks:
      - kryonix_network
    depends_on:
      - analytics-service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  timescaledb_data:
    driver: local
  clickhouse_data:
    driver: local
  elasticsearch_data:
    driver: local

EOL

    log_success "Docker Compose configurado"
}

# Criar estrutura de diret√≥rios
create_directories() {
    log_info "Criando estrutura de diret√≥rios..."
    
    mkdir -p "$PROJECT_ROOT"/{
        src/services/analytics/{entities,dto,interfaces,processors},
        src/components/analytics/{dashboards,widgets,charts,reports},
        src/hooks/analytics,
        docker/{timescaledb,clickhouse,elasticsearch,analytics,ml-service},
        ml-models,
        ml-data,
        reports,
        logs/{analytics,ml},
        backups/{timescaledb,clickhouse,elasticsearch}
    }
    
    log_success "Estrutura de diret√≥rios criada"
}

# Configurar Nginx
configure_nginx() {
    log_info "Configurando Nginx para Analytics..."
    
    cat >> "$PROJECT_ROOT/docker/nginx/conf.d/analytics.conf" << 'EOL'
# Analytics Service
upstream analytics_backend {
    server analytics-service:3010;
}

# Analytics WebSocket
upstream analytics_ws {
    server analytics-service:3010;
}

server {
    listen 80;
    server_name analytics.kryonix.local;

    # Analytics API
    location /api/analytics/ {
        proxy_pass http://analytics_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket support
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    # Analytics WebSocket
    location /socket.io/ {
        proxy_pass http://analytics_ws;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Reports download
    location /reports/ {
        alias /app/reports/;
        expires 1h;
        add_header Cache-Control "public, immutable";
    }
}

# ML Service
upstream ml_backend {
    server ml-service:8080;
}

server {
    listen 80;
    server_name ml.kryonix.local;

    location / {
        proxy_pass http://ml_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
EOL

    log_success "Nginx configurado"
}

# Inicializar bancos de dados
initialize_databases() {
    log_info "Inicializando bancos de dados..."
    
    # Aguardar servi√ßos iniciarem
    sleep 30
    
    # Executar migrations do TimescaleDB
    docker-compose exec timescaledb psql -U kryonix_analytics -d kryonix_analytics -f /docker-entrypoint-initdb.d/01-create-analytics-db.sql
    
    # Executar setup do ClickHouse
    docker-compose exec clickhouse clickhouse-client --multiquery < /docker-entrypoint-initdb.d/01-create-tables.sql
    
    # Configurar √≠ndices no Elasticsearch
    curl -X PUT "localhost:9200/analytics-events" -H "Content-Type: application/json" -d '{
        "mappings": {
            "properties": {
                "tenant_id": { "type": "keyword" },
                "event_type": { "type": "keyword" },
                "timestamp": { "type": "date" },
                "user_id": { "type": "keyword" },
                "properties": { "type": "object" },
                "location": { "type": "geo_point" }
            }
        }
    }'
    
    log_success "Bancos de dados inicializados"
}

# Configurar monitoramento
setup_monitoring() {
    log_info "Configurando monitoramento espec√≠fico para Analytics..."
    
    # Grafana dashboard para Analytics
    cat > "$PROJECT_ROOT/monitoring/grafana/dashboards/analytics.json" << 'EOL'
{
    "dashboard": {
        "title": "KRYONIX Analytics & BI",
        "panels": [
            {
                "title": "Events per Hour",
                "type": "graph",
                "targets": [
                    {
                        "expr": "rate(analytics_events_total[1h])",
                        "legendFormat": "{{event_type}}"
                    }
                ]
            },
            {
                "title": "Active Users",
                "type": "stat",
                "targets": [
                    {
                        "expr": "analytics_active_users",
                        "legendFormat": "Active Users"
                    }
                ]
            },
            {
                "title": "Dashboard Load Time",
                "type": "histogram",
                "targets": [
                    {
                        "expr": "analytics_dashboard_load_duration_seconds",
                        "legendFormat": "Load Time"
                    }
                ]
            }
        ]
    }
}
EOL

    log_success "Monitoramento configurado"
}

# Configurar alertas
setup_alerts() {
    log_info "Configurando alertas espec√≠ficos..."
    
    cat > "$PROJECT_ROOT/monitoring/alertmanager/analytics-rules.yml" << 'EOL'
groups:
  - name: analytics
    rules:
      - alert: HighEventVolume
        expr: rate(analytics_events_total[5m]) > 1000
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High event volume detected"
          description: "Event volume is {{ $value }} events/sec"
      
      - alert: DashboardLoadSlow
        expr: analytics_dashboard_load_duration_seconds > 5
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Dashboard loading slowly"
          description: "Dashboard load time is {{ $value }} seconds"
      
      - alert: AnalyticsServiceDown
        expr: up{job="analytics-service"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Analytics service is down"
          description: "Analytics service has been down for more than 1 minute"
EOL

    log_success "Alertas configurados"
}

# Executar testes
run_tests() {
    log_info "Executando testes do sistema de Analytics..."
    
    cd "$PROJECT_ROOT"
    
    # Testes de unidade
    npm test -- --testPathPattern=analytics
    
    # Testes de integra√ß√£o
    npm run test:integration -- --testPathPattern=analytics
    
    # Testes de performance
    npm run test:performance -- --testPathPattern=analytics
    
    log_success "Testes executados com sucesso"
}

# Fun√ß√£o principal
main() {
    echo "üöÄ Configura√ß√£o do KRYONIX Analytics & BI"
    echo "======================================="
    
    check_dependencies
    create_directories
    setup_environment
    setup_timescaledb
    setup_clickhouse
    setup_elasticsearch
    install_dependencies
    setup_docker_compose
    configure_nginx
    setup_monitoring
    setup_alerts
    
    log_info "Iniciando servi√ßos..."
    cd "$PROJECT_ROOT"
    docker-compose up -d timescaledb clickhouse elasticsearch analytics-service ml-service
    
    log_info "Aguardando servi√ßos iniciarem..."
    sleep 60
    
    initialize_databases
    run_tests
    
    echo ""
    log_success "‚úÖ Sistema de Analytics e BI configurado com sucesso!"
    echo ""
    echo "üìä Servi√ßos dispon√≠veis:"
    echo "  - TimescaleDB: http://localhost:5433"
    echo "  - ClickHouse: http://localhost:8123"
    echo "  - Elasticsearch: http://localhost:9200"
    echo "  - Analytics API: http://localhost:3010"
    echo "  - ML Service: http://localhost:8080"
    echo ""
    echo "üîç Dashboards:"
    echo "  - Analytics: http://analytics.kryonix.local"
    echo "  - ML Insights: http://ml.kryonix.local"
    echo ""
    echo "üìà Pr√≥ximos passos:"
    echo "  1. Configurar dashboards no Grafana"
    echo "  2. Criar relat√≥rios personalizados"
    echo "  3. Configurar alertas espec√≠ficos"
    echo "  4. Treinar modelos de ML"
    echo ""
}

# Verificar se o script est√° sendo executado diretamente
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
```

## ‚úÖ Checklist de Valida√ß√£o

### Funcionalidades B√°sicas
- [ ] Coleta de eventos em tempo real
- [ ] Armazenamento em TimescaleDB
- [ ] Processamento em lote no ClickHouse
- [ ] Indexa√ß√£o no Elasticsearch
- [ ] Cache Redis funcionando
- [ ] WebSocket para tempo real

### Dashboards e Visualiza√ß√µes
- [ ] Cria√ß√£o de dashboards
- [ ] Widgets configur√°veis
- [ ] Filtros din√¢micos
- [ ] Modo de edi√ß√£o
- [ ] Compartilhamento de dashboards
- [ ] Responsividade mobile

### Relat√≥rios e Exports
- [ ] Gera√ß√£o de relat√≥rios PDF
- [ ] Export para Excel/CSV
- [ ] Agendamento de relat√≥rios
- [ ] Email autom√°tico
- [ ] Relat√≥rios em tempo real

### Alertas e Notifica√ß√µes
- [ ] Cria√ß√£o de regras de alerta
- [ ] Detec√ß√£o de anomalias
- [ ] Notifica√ß√µes WebSocket
- [ ] Integra√ß√£o com email/Slack
- [ ] Escala√ß√£o de alertas

### Intelig√™ncia Artificial
- [ ] Gera√ß√£o de insights
- [ ] Previs√µes de tend√™ncias
- [ ] Detec√ß√£o de padr√µes
- [ ] Recomenda√ß√µes autom√°ticas
- [ ] An√°lise de sentimento

### Performance e Escalabilidade
- [ ] Compress√£o TimescaleDB
- [ ] Particionamento de dados
- [ ] Cache otimizado
- [ ] Queries eficientes
- [ ] Reten√ß√£o de dados

### Seguran√ßa e Compliance
- [ ] Row Level Security
- [ ] Isolamento por tenant
- [ ] Auditoria de acesso
- [ ] Compliance LGPD/GDPR
- [ ] Anonimiza√ß√£o de dados

## üß™ Testes

### Testes de Unidade
```bash
npm test -- --testPathPattern=analytics/services
npm test -- --testPathPattern=analytics/components
```

### Testes de Integra√ß√£o
```bash
npm run test:integration -- --testPathPattern=analytics
```

### Testes de Performance
```bash
npm run test:performance -- --testPathPattern=analytics
npm run test:load -- --testPathPattern=analytics
```

### Testes E2E
```bash
npm run test:e2e -- --testPathPattern=analytics
```

---

**PARTE 29 CONCLU√çDA COM SUCESSO! ‚úÖ**

Sistema completo de Analytics e Business Intelligence implementado com:
- TimescaleDB para s√©ries temporais
- ClickHouse para agrega√ß√µes r√°pidas  
- Elasticsearch para busca e ML
- Dashboards interativos com React
- Relat√≥rios automatizados
- Alertas inteligentes
- IA para insights preditivos
- WebSocket para tempo real
- Compliance com LGPD/GDPR
